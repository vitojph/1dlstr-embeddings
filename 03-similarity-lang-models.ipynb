{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a720367-8920-4820-b737-029ccc79c7f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-18T14:46:30.801437Z",
     "iopub.status.busy": "2022-03-18T14:46:30.801164Z",
     "iopub.status.idle": "2022-03-18T14:46:30.815892Z",
     "shell.execute_reply": "2022-03-18T14:46:30.815408Z",
     "shell.execute_reply.started": "2022-03-18T14:46:30.801355Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@import url('https://fonts.googleapis.com/css?family=Montserrat');\n",
       "\n",
       "h1, h2, h3 {\n",
       "    font-family: Montserrat;\n",
       "    font-weight: bold;\n",
       "    position: static;\n",
       "    color: #ffcf21;\n",
       "}\n",
       "\n",
       "p, li {\n",
       "    font-family: Montserrat;\n",
       "    size: 11px;\n",
       "    text-align: justify;\n",
       "    text-justify: inter-word;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# esta celda controla el estilo del cuaderno\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14cfa95-bb37-4e9f-9ec4-f30d0ca58641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install docarray\n",
    "!pip install sentence_transformers\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2757614d-d665-404d-8576-37a43418ef7b",
   "metadata": {},
   "source": [
    "# Modelos de Lenguaje y Similitud Semántica\n",
    "\n",
    "En esta presentación vamos a continuar trabajando con modelos de lenguaje ya pre-entrenados, intentando entender cómo funcionan y viendo ejemplos concretos de uso.\n",
    "\n",
    "\n",
    "## HuggingFace\n",
    "\n",
    "[HuggingFace](https://huggingface.co) se ha convertido en todo un reference en el mundo del PLN. \n",
    "\n",
    "- fueron los primeros en distribuir una versión de BERT compatible con PyTorch.\n",
    "- crearon un interfaz interoperable entre TensorFlow y PyTorch.\n",
    "- su librería `transformers` permite acceder a decenas de modelos con arquitecturas diferentes con una interfaz común.\n",
    "- su librería `datasets` permite acceder a decenas de datasets e interaccionar con nuestros propios datos de manera sencilla \n",
    "- han creado un repositorio de modelos de lenguaje\n",
    "\n",
    "Vamos a recorrer uno de sus principales recursos: la [central de modelos](https://huggingface.co/models), un repositorio público de modelos de lenguaje ya preentrenados.\n",
    "\n",
    "DistilGPT-2 es una versión de tamaño reducido del célebre modelo [GPT-2](https://openai.com/blog/better-language-models/), desarrollado por OpenAI en 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe68717-1b10-4f96-98ae-83c21b3220d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c02b016-72c8-495e-b24e-9171b48fd86f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "gpt2_model.to(device)\n",
    "gpt2_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59af8e-98b7-4079-a3bf-2fce7263d56b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"The US president announced earlier today\"\"\"\n",
    " \n",
    "input_ids = torch.tensor(gpt2_tokenizer.encode(text, add_special_tokens=True)).unsqueeze(0)\n",
    " \n",
    "outputs = gpt2_model.generate(\n",
    "    input_ids.to(device), \n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    top_k=20,\n",
    "    temperature=0.7\n",
    "    )\n",
    " \n",
    "print(gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "# outputs.shape,outputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e2733-d390-4efc-84a9-b919f8da75c4",
   "metadata": {},
   "source": [
    "[GPT-3](https://openai.com/blog/gpt-3-apps/) es la última versión de este modelo de lenguaje masivo desarrollado por OpenAI, publicada en 2021. [No está disponible en abierto](https://gpt3-openai.com/), pero un grupo de investigadores llamado [Eleuther AI](https://www.eleuther.ai/) ha entrenado una versión alternativa por su cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124bfcb-db29-4bb5-913a-d0babc33be95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt3_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "gpt3_model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "gpt3_model.to(device)\n",
    "gpt3_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02198a5-272e-483f-ba77-642c96804380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"The US president announced earlier today\"\"\"\n",
    " \n",
    "input_ids = torch.tensor(gpt3_tokenizer.encode(text, add_special_tokens=True)).unsqueeze(0)\n",
    " \n",
    "outputs = gpt3_model.generate(\n",
    "    input_ids.to(device), \n",
    "    max_length=50,\n",
    "    do_sample=True,\n",
    "    top_k=20,\n",
    "    temperature=0.7\n",
    "    )\n",
    " \n",
    "print(gpt3_tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "# outputs.shape,outputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f0f73-7f86-453f-be44-51dceb20ec28",
   "metadata": {},
   "source": [
    "## Modelos de similitud semántica\n",
    "\n",
    "El model hub de HF dispone de una buena variedad de [modelos de lenguaje ajustados para tareas de similitud semántica](https://huggingface.co/models?pipeline_tag=sentence-similarity&sort=downloads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38668e-147f-403e-baac-04108e018f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "ss_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875b8ab-c1bc-4e8e-ba20-9fe56fd8bf21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = ss_model.encode(\"I love tacos and micheladas\")\n",
    "\n",
    "print(embedding.shape)\n",
    "print(embedding[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009f9fc-248f-427f-ba58-69f7efb2d7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = ss_model.encode([\"I don't like it\", \"I like it\"])\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d3872-bb32-40e6-955d-7a0c424d2968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # Smartphones\n",
    "    \"I like my phone\",\n",
    "    \"My phone is not good.\",\n",
    "    \"Your cellphone looks great.\",\n",
    "\n",
    "    # Weather\n",
    "    \"Will it snow tomorrow?\",\n",
    "    \"Recently a lot of hurricanes have hit the US\",\n",
    "    \"Global warming is real\",\n",
    "\n",
    "    # Food and health\n",
    "    \"An apple a day, keeps the doctors away\",\n",
    "    \"Eating strawberries is healthy\",\n",
    "    \"Is paleo better than keto?\",\n",
    "\n",
    "    # Asking about age\n",
    "    \"How old are you?\",\n",
    "    \"what is your age?\",\n",
    "    \"Am I younger than you?\",\n",
    "]\n",
    "\n",
    "embeddings_en = ss_model.encode(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7390d1e-f801-4e3f-a08d-93ef4cda8a48",
   "metadata": {},
   "source": [
    "Una vez codificados nuestros textos de ejemplo como vectores, vamos a crear una base de datos de embeddings de manera que podamos lanzar búsquedas basadas en similitud semántica. Para ello, vamos a aprovechar la librería [DocArray](https://docarray.jina.ai/) de [Jina.ai](https://jina.ai), otra empresa de la que merece estar al tanto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba13ba-5d5b-486e-bee3-43d24ed0d0d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from docarray import DocumentArray, Document\n",
    "\n",
    "da = DocumentArray([Document(text=m, embedding=embeddings_en[i]) for i, m in enumerate(messages)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e081e2-72ad-48e8-8cd2-8edfff2aa1f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def similarity_search(\n",
    "    q: str, \n",
    "    model: SentenceTransformer = ss_model, \n",
    "    da: DocumentArray = da,\n",
    "    n: int = 3\n",
    ") -> None:\n",
    "    query = (\n",
    "        Document(text=q, embedding=model.encode(q))\n",
    "        .match(da, limit=n, exclude_self=True, metric=\"cosine\")\n",
    "        )\n",
    "\n",
    "    return [(m.text, m.scores[\"cosine\"].value) for m in query.matches]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbed5e-acf3-4548-80af-654a4ba48151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_search(q=\"My handheld device has two screens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91808be0-b3be-467e-bae1-de4431df74fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_search(q=\"Mostly dry. Freeze-thaw conditions (max 50°F on Mon afternoon, min 32°F on Tue night).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7869d98-2058-487b-8ce2-9f49303e5476",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_search(q=\"I'm 40 years old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93632d84-8b9c-4240-a850-ad03f6f1f6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_similarity(labels, features):\n",
    "    \"\"\"Dibuja un mapa de calor con las distancias de similitud\"\"\"\n",
    "    corr = np.inner(features, features)\n",
    "    sns.set(font_scale=1.2)\n",
    "    g = sns.heatmap(\n",
    "        corr,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        cmap=\"YlOrRd\")\n",
    "    g.set_xticklabels(labels, rotation=90)\n",
    "    g.set_title(\"Similitud Semántica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618cd167-6971-437e-8f5a-6e683de2d33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_similarity(messages, embeddings_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3cf00c-2234-4fbe-a511-1fc0123c448d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ss_model_es = SentenceTransformer(\"hiiamsid/sentence_similarity_spanish_es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84fcb1d-4d50-4888-b600-89f84d7714c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mensajes = [\n",
    "    \"Me gusta mi teléfono.\",\n",
    "    \"Mi móvil no es muy bueno.\",\n",
    "    \"Tu teléfono parece caro.\",\n",
    "\n",
    "    \"¿Va a nevar mañana?\",\n",
    "    \"Ha habido muchos huracanes en EEUU este año\",\n",
    "    \"El calentamiento global es real\",\n",
    "\n",
    "    \"El que come una manzana aleja al médico de su cama\",\n",
    "    \"Comer fruta y verdura es muy saludable\",\n",
    "    \"¿Es mejor hacer dieta paleo o keto?\",\n",
    "\n",
    "    \"¿Cuántos años tienes?\",\n",
    "    \"¿Cuál es tu edad?\",\n",
    "    \"¿Soy más joven que usted o más viejo?\",\n",
    "]\n",
    "\n",
    "embeddings_es = ss_model_es.encode(mensajes)\n",
    "da_es = DocumentArray([Document(text=m, embedding=embeddings_es[i]) for i, m in enumerate(mensajes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645285b3-de9c-421e-8b19-848e401bb4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(embeddings_es.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4d5b9-9f46-4c95-8377-a3382987f5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_search(q=\"Samsung, Xiaomi y Apple se reparten el mercado\", model=ss_model_es, da=da_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbea6c-693b-4d30-9521-5012641fbd67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_search(q=\"No soy un niñato, tengo más de 40 palos\", model=ss_model_es, da=da_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a1286-4ac6-43a6-989d-0da0e76e5163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "similarity_search(q=\"Podría comer gazpacho y tortilla de patatas todos los días\", model=ss_model_es, da=da_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321ccebb-d6a5-4b60-8f85-4e7a89896927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_similarity(mensajes, embeddings_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af893c-6f4d-4c58-8c31-abfb64fa8736",
   "metadata": {},
   "source": [
    "## Universal Sentence Encoder\n",
    "\n",
    "El ecosistema TensorFlow tiene su propio repositorio público de modelos: [TFHub](https://tfhub.dev). Hay varios modelos, pero probablemente uno de los más interesantes es [Universal Sentence Encoder (USE)](https://tfhub.dev/google/universal-sentence-encoder/4).\n",
    "\n",
    "Al contrario que los anteriores, estos modelos de lenguaje no están basado en la arquitectura de Transformer, sino que utiliza otro tipo de red neuronal llamado *Deep Averaging Network* (DAN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ac868-24d6-4ba9-a676-f7fa325ded1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install tensorflow tensorflow_hub tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f001db-8316-44fe-9a25-6d37c84d0f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fda785-f419-44ad-850e-b855420b6116",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "USE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "use_model = hub.load(USE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5ade8-6cfe-4c00-8d38-a39b137a78c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = use_model([\"hello\"])\n",
    "e[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21de69-5263-4b7f-9784-9b583f28bf86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_embeddings = use_model(messages)\n",
    "print(use_embeddings.shape)\n",
    "\n",
    "use_da = DocumentArray([Document(text=m, embedding=use_embeddings[i]) for i, m in enumerate(messages)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1f669-0714-49f8-a2df-e3426e36d5a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def use_similarity_search(\n",
    "    q: str, \n",
    "    model, \n",
    "    da,\n",
    "    n: int = 3\n",
    ") -> None:\n",
    "    query = (\n",
    "        Document(text=q, embedding=model([q])[0])\n",
    "        .match(da, limit=n, exclude_self=True, metric=\"cosine\")\n",
    "        )\n",
    "\n",
    "    return [(m.text, m.scores[\"cosine\"].value) for m in query.matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1e5a1-86ac-42db-b9b8-62a20c174130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_similarity_search(q=\"My handheld device has two screens\", model=use_model, da=use_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b5292-e1c5-4789-9e06-5bb31f5b4bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_similarity_search(q=\"Mostly dry. Freeze-thaw conditions (max 50°F on Mon afternoon, min 32°F on Tue night).\", model=use_model, da=use_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc86db3-02c0-44c4-92f2-f90f764cb994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_similarity_search(q=\"I'm 40 years old\", model=use_model, da=use_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58965041-92ea-42e4-887d-2d228b32585e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_similarity(messages, use_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f7074-f6ec-43f1-8eb1-666c30153201",
   "metadata": {},
   "source": [
    "¿Qué tal funciona USE en español? No hay un modelo monolingüe específico, pero sí [existe una variante multilingüe que se ha entrenado en varios idiomas](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3). Probemos uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703aa7ec-4291-4a06-b22c-d39db78e77e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MULTI_USE_URL = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\"\n",
    "multi_use_model = hub.load(MULTI_USE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8256f9-0005-48bd-9075-da8a653636a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_embeddings_es = multi_use_model(mensajes)\n",
    "print(use_embeddings_es.shape)\n",
    "\n",
    "use_da_es = DocumentArray([Document(text=m, embedding=use_embeddings_es[i]) for i, m in enumerate(mensajes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f139bcd-6b16-4bfe-9a48-c94ef983f400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_similarity_search(q=\"Samsung, Xiaomi y Apple se reparten el mercado\", model=multi_use_model, da=use_da_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65895f-0bfb-40ca-9ca5-53996a03caf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_similarity_search(q=\"No soy un niñato, tengo más de 40 palos\", model=multi_use_model, da=use_da_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457e939c-f630-4ce5-9b9e-9764b3b18070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_similarity_search(q=\"Podría comer gazpacho y tortilla de patatas todos los días\", model=multi_use_model, da=use_da_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc94719b-70e1-4075-9bcf-af1eafdcfcf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_similarity(mensajes, use_embeddings_es)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
